# BloombergGPT_My_Early_Commentary
BloombergGPT is told to be a revolutionary large language model bringing new quality into financial data analysis. Is it really so and what does BloombergGPT have on offer? My personal commentary on the matter.

As of October 2023, Polish language version of the commentary is available.

--------------------------------------------------------------------------

## BloombergGPT – odpowiednik ChatGPT dla sektora finansowego? 
Zapraszam do przeczytania mojej wypowiedzi na ten temat.
Marta Mężykowska, 08.10.2023 r.

-----------------------------------------------------------------------

## Spis treści
   * [Generatywna sztuczna inteligencja](#Generatywna-sztuczna-inteligencja)
   * [BloombergGPT AI w służbie świata finansów](#BloombergGPT-AI-w-słuzbie-swiata-finansow)
   * [BloombergGPT metodologia modelu](#BloombergGPT-metodologia-modelu)
   * [BloombergGPT omówienie wyników](#BloombergGPT-omówienie-wyników)
   * [BloombergGPT podsumowanie i niuanse](#BloombergGPT-podsumowanie-i-niuanse)
   * [Bibliografia](#Bibliografia)

-------------------------------------------------------------------

## Generatywna sztuczna inteligencja

  W ostatnim czasie newsfeedy zostały wprost zalane informacjami na temat ChatGPT – chatbota opartego na sztucznej inteligencji, który został udostępniony przez firmę OpenAI bezpłatnie dla każdego zalogowanego uczestnika. Do tej pory wydawało się, iż korzystanie z osiągnięć sztucznej inteligencji możliwe jest jedynie dla wąskiego i wyspecjalizowanego grona osób, tymczasem ChatGPT uzmysłowił przeciętnemu             użytkownikowi Internetu potencjał, jaki kryje się w wykorzystaniu modeli opartych na AI (tzw. LLM-ów*) do zadań z zakresu pogłębionej analizy tekstu, generowania spersonalizowanych treści i wyszukiwań.  Choć     ChatGPT nie jest nieomylny, a także trzeba wiedzieć w jaki sposób z nim rozmawiać, aby uzyskać wartościową i najlepiej dopasowaną do oczekiwań odbiorcy odpowiedź,  nie ulega wątpliwości, iż odniósł niesamowity sukces i optymalizuje ludzką pracę w wielu dziedzinach.

  (*LLM – ang. „Large Language Model” – dosłownie „Duży model językowy” - model językowy oparty na sztucznej inteligencji, trenowany na ogromnych zbiorach danych i osiągający wysoką w porównaniu z innymi modelami skuteczność. Zasadniczo stworzenie takiego modelu uczenia maszynowego wymaga udostępnienia ogromnej mocy obliczeniowej i jego wieloetapowego treningu, przez co jest to osiągalne praktycznie tylko dla\lub we współpracy z wiodącymi firmami technologicznymi.)

  Funkcjonalności, których oczekiwać można od ChatGPT to przede wszystkim odpowiadanie przez bota na zadane pytania. Chatbot będzie generował odpowiedź dla użytkownika, jeśli zajdzie taka potrzeba może także dane „w tle” przetwarzać, podsumowywać czy przeredagowywać, tak by przedstawić finalny efekt zgodnie z oczekiwaniem rozmówcy. Możemy zasugerować mu formę czy długość odpowiedzi, możemy także poprosić o wygenerowanie raportu, prezentacji czy dokumentu na konkretny temat. Na dzień dzisiejszy kwestie praw autorskich do wygenerowanych przez bota odpowiedzi w większości krajów są jeszcze nieuregulowane, choć zdarzały się już pierwsze procesy sądowe na ten temat.   

  Lawinowo rosnące zainteresowanie modelami sztucznej inteligencji postanowili wykorzystać inni giganci technologiczni prezentując swoje osiągnięcia w tej dziedzinie. Dużo emocji wywołuje chatbot Bard od Google, bezpośrednia konkurencja dla ChatGPT w sektorze generatywnej sztucznej inteligencji ogólnego przeznaczenia. Kolejne rozwiązania prezentują także firmy takie jak Microsoft, Meta czy NVIDIA.

-------------------------------------------------------------------

## BloombergGPT – AI w służbie świata finansów

  Tymczasem obok starcia na szczycie, nieco w cieniu, dzieją się równie ciekawe rzeczy. A mianowicie powstają wyspecjalizowane modele językowe, oparte na sztucznej inteligencji, dostosowane dla konkretnych branż i odbiorców. Czy możemy jednak liczyć na dokładne odwzorowanie modelu biznesowego firm pokroju OpenAI czy Google w tym zakresie? O tym poniżej.

  30 marca 2023 r., a więc dokładnie 4 miesiące po tym jak OpenAI upubliczniło dostęp do ChatGPT, międzynarodowa agencja prasowa Bloomberg L.P. ogłosiła pierwsze szczegółowe informacje na temat BloombergGPT - rozwijanego przez siebie modelu językowego opartego na sztucznej inteligencji dedykowanego środowisku finansowemu. BloombergGPT ma radzić sobie znacznie lepiej z zapytaniami z zakresu finansów wśród modeli uczenia maszynowego o podobnej wielkości. Z udostępnionych przez firmę informacji możemy dowiedzieć się także, iż BloombergGPT jest wyczulony na uwzględnienie specyficznego kontekstu informacji widzianego z perspektywy świata finansów. Wśród innych zapewnień firma posuwa się także do stwierdzenia, iż BloombergGPT radzi sobie tylko niewiele gorzej, o ile wcale, z odpowiedziami na pytania „general purpose”, czyli ogólnego przeznaczenia, w których prym wiodą duże modele językowe pokroju ChatGPT czy Bard.

  Zanim przejdziemy jednak do szczegółowych analiz, poświęćmy chwilę firmie Bloomberg L.P. samej w sobie. Siedziba firmy znajduje się na Manhattanie w Nowym Jorku w USA, a jej korzenie sięgają 1981 roku. Bloomberg znany jest przede wszystkim jako jeden z największych i najbardziej wpływowych prywatnych serwisów informacyjnych na świecie, dostarczający codziennie informacje na temat spraw bieżących, ekonomii, finansów, polityki, technologii i innych. Firma świadczy także szeroko pojęte usługi z zakresu finansów, technologii i analizy danych. Bloomberg jest aktywny w mediach konwencjonalnych, jak i społecznościowych, publikuje branżowe raporty i statystyki, a także posiada zintegrowane narzędzie  dedykowane inwestorom indywidualnym i korporacyjnym zwane Bloomberg Terminal. (Za podobny w pewnym sensie, aczkolwiek lokalny polski odpowiednik serwisu informacyjnego Bloomberg można podać serwis bankier.pl. )

  Czym dokładnie jest Bloomberg Terminal? Jest to narzędzie stworzone z myślą o inwestorach giełdowych oraz interesariuszach szeroko pojętego sektora finansów. Bloomberg Terminal to portal internetowy umożliwiający dostęp w jednym miejscu oraz w czasie rzeczywistym do danych finansowych pochodzących z oficjalnych publikacji podmiotów prywatnych i instytucji rządowych z całego świata, jak i wykonanych na ich podstawie przez program własnych raportów i analiz finansowych czy ocen ryzyka. Bloomberg Terminal może posłużyć nie tylko do wyszukania konkretnej firmy i jej profilu finansowego, dostarczy informacji o jej strukturze kapitału, akcjonariacie, wynikach na giełdzie czy ogólnej ocenie ryzyka inwestycyjnego, wszystko w ujęciu czasowym. Patrzeć na dane możemy także z makroekonomicznego punktu widzenia:  znajdziemy tu informacje w podziale na sektory gospodarcze, kraje, rynki, giełdy, indeksy czy poszczególne typy instrumentów finansowych. Dodatkowo terminal posiada także zintegrowany news feed oraz umożliwia bezpośrednie inwestowanie (zakup instrumentów finansowych). Można by powiedzieć, wszystko dla inwestora w jednym miejscu.

  Pozostaje pytanie: jaką wartość dodaną może wnieść BloombergGPT do Blommberg Terminal? Uogólniając, można by powiedzieć, iż Bloomberg Terminal jest solidną bazą wiedzy na temat zjawisk w obrębie sektora finansów, natomiast BloombergGPT ma być „silnikiem”, który po podpięciu do danych umożliwi ich szybszą, efektywniejszą i bardziej kompleksową analizę. Dokładnie tak jak w przypadku ChatGPT, narzędzie Bloomberga powinno pozwolić na szybkie i skuteczne wyszukiwanie oraz generowanie spersonalizowanych treści na indywidualne zapytania. Byłoby to szczególnie przydatne w przypadku, gdyby odpowiedź wymagała korzystania z więcej niż jednego źródła, podsumowania czy pogrupowania danych lub przygotowania prostej wizualizacji. 

  BloombergGPT ma integrować funkcjonalności charakterystyczne dla  modeli uczenia maszynowego z zakresu NLP (NLP – ang. „Natural Language Processing” – „przetwarzanie języka naturalnego”, znacznie upraszczając, jest to ogół procesów prowadzących do generowania przez maszynę tekstu wartościowego i zrozumiałego dla człowieka). W tym rozumieniu firma Bloomberg wskazuje na skuteczne zastosowanie BloombergGPT m.in. do klasyfikacji wiadomości (newsów), rozpoznawania encji (NER) czy analizy sentymentu. Poświęcę tutaj chwilę każdej z tych kategorii.

  Klasyfikacja jest szerokim tematem w ujęciu uczenia maszynowego (ang. “Machine learning”), a jej celem jest poprawne przypisanie obiektu do odpowiedniej kategorii (klasy). Klasyfikacja binarna dopuszcza dwie klasy: mogą być to na przykład prawda i fałsz, oznaczające spełnienie warunku klasyfikacji lub jego niespełnienie. Możemy podzielić firmy na publiczne lub prywatne, notowane na giełdzie lub nie, kandydatów na pracowników na karanych lub o nienagannej przeszłości. Inny rodzaj klasyfikacji to wieloklasowa: jak łatwo się domyślić, potencjalnych kategorii przypisania jest tu więcej. Przykładem może być unijna klasyfikacja przedsiębiorstw na mikro, małe, średnie i duże przedsiębiorstwa.  

  W zależności od klasyfikatora możemy starać się przypisywać wiadomości do odpowiednich kategorii tematycznych (autotagowanie), ustawiać alerty (ważne-nieważne, pilne-niepilne itp.), odfiltrowywać spam, podpowiadać powiązane treści, podzielić klientów na kategorie. Odpowiednie zaklasyfikowanie informacji jest wstępnym krokiem pozwalającym na wysoką efektywność przetwarzania informacji.  

  Kolejnym aspektem wartym wyjaśnienia jest rozpoznawanie encji (z ang. NER – „Named Entity Recognition”). Za encję uznaje się określony obiekt, możliwy do wyróżnienia na tle innych obiektów w tekście. Przykładami encji w tekście mogą być podmiot lub osoba (LPP SA, Andrzej Duda), miejsce (Gdańsk), rzecz (Fiat 126p), ale także podjęcia niematerialne i abstrakcyjne (wojna, konto bankowe, hasło np. ostry cień mgły). W tekście oznaczać można więcej niż jedną encję, a relacje je łączące mogą tworzyć swoiste „siatki zależności”, które także mogą być poddawane analizie. 

  Analiza encji jest dla człowieka bardzo intuicyjna. Słuchając wiadomości, czytając newsy czy informacje ze świata social mediów bez problemu identyfikujemy obiekty o specyficznym znaczeniu. Algorytmy uczenia maszynowego muszą jednak nauczyć się analizy tekstu z ujęciem specyficznego kontekstu w jakim słowo jest osadzone, języka o konkretnej składni oraz poruszania w złożonym świecie wyrazów wieloznacznych. Poprawne oznaczanie encji jest kluczowe dla skutecznego działania wyszukiwarek i znajdowania właściwych odpowiedzi na zadane przez użytkowników pytania.

  Ważnym zagadnieniem z dziedziny NLP jest analiza sentymentu (ang. „Sentiment Analysis”). Analiza sentymentu jest analizą tekstu (np. wypowiedzi, artykułu prasowego) służącą określeniu zaangażowania emocjonalnego autora oraz potencjalnego efektu wywołanego u odbiorcy. Jeśli pani Kowalska przeczyta w Internecie negatywny komentarz napisany przez pana Nowaka na temat frytek z McDonalda, zgodnie z analizą sentymentu możemy wywnioskować, iż a) pan Nowak ma negatywny sentyment wobec frytek z McDonalda, b) pani Kowalska może nie zakupić tych frytek kierując się negatywną opinią pana Nowaka. Wbrew pozorom analiza sentymentu nie jest niczym nowym, najprostszym jej przykładem są różnego rodzaju sondaże przeprowadzane w okresie przedwyborczym czy badania opinii konsumentów. Z perspektywy przedsiębiorstwa czy instytucji, poznanie sentymentu na temat firmy, oferowanych produktów czy usług, czołowych pracowników, działań społeczno-politycznych czy oczekiwań interesariuszy może okazać się kluczowe dla kreowania wizerunku, działań marketingowych, biznesowych sojuszy zawieranych przez firmę czy finalnego efektu w postaci wolumenu sprzedaży produktów i usług.  Co więcej, wczesne (wcześniejsze niż konkurencja) rozpoznanie trendów, zmian i nastrojów może być znaczącą przewagą rynkową  dla przedsiębiorstwa. Stąd też korzyści z zastosowania analizy sentymentu mogą być dla firm ogromne.

  W odniesieniu do modeli językowych opartych na sztucznej inteligencji, analiza sentymentu podmiotu z otoczenia finansowego mogłaby polegać na analizie wiadomości, oczekiwań i reakcji dotyczących wprowadzenia nowego produktu czy usługi, wyników okresowych i giełdowych, dywidendy, otoczenia rynkowego (jak firma odnajduje się w bieżącej sytuacji rynkowej?), odbioru komunikatów stosowanych przez firmę do interesariuszy i innych informacji z nią związanych. Nie bez znaczenia jest tutaj aspekt czasowy - dane w postaci newsów mogą być analizowane natychmiast po zdarzeniu, dostarczają więc szybkiego i kompleksowego feedbacku na temat odbioru sytuacji przez publikę oraz umożliwiają dostosowanie polityki informacyjnej podmiotu pod bieżące zapotrzebowanie i oczekiwania.

  W swojej publikacji „BloombergGPT: A Large Language Model for Finance” z 30.03.2023 r.  (wersja zaktualizowana 09.05.2023 r.; dalej będę odnosić się do niej jako ‘Paper’; str. 19) Bloomberg posuwa się do przedstawienia jeszcze śmielszego przykładu, w którym wskazuje na przewagi konkurencyjne BloombergGPT w zakresie analizy sentymentu. Firma stwierdza, iż jej model jest w stanie znacząco lepiej odczytywać sentyment z wiadomości o tematyce finansowej z punktu widzenia potencjalnego inwestora niż inne LLMy. Aby to zobrazować posłużono się następującym przykładem: w Sieci pojawia się wiadomość prasowa „Firma XYZ zwolni 10 000 pracowników”. Z punktu widzenia szerokiego grona odbiorców taka informacja wzbudzi negatywny sentyment (ludzie tracący pracę pozostają bez środków do życia, redukcja etatów popularnie kojarzona z ograniczeniem nierentownej działalności = kłopoty w biznesie). BloombergGPT natomiast, stawiając się w pozycji inwestora, mógłby taką wiadomość w określonych przypadkach oznaczyć jako wywołującą sentyment pozytywny – np. gdyby sprzedaż nierentownej i nierokującej części działalności miała poprawić płynność finansową firmy XYZ oraz wzmocnić jej pozycję na rynku i koncentrację kompetencji w segmentach strategicznych, co stanowiłoby pozytywny sygnał do generowania przyszłych zysków. Brzmi ciekawie?

-------------------------------------------------------------------

## BloombergGPT – metodologia modelu

  W publikacji (Paper, od str. 11) możemy dowiedzieć się wielu szczegółów na temat założeń i metodologii towarzyszących tworzeniu modelu BloombergGPT.  Kilka najważniejszych przedstawiam poniżej.

  BloombergGPT jest modelem zbudowanym na architekturze transformerów, a jego  bezpośrednim „rodzicem” jest dostępny publicznie LLM „BLOOM” (https://huggingface.co/docs/transformers/model_doc/bloom#transformers.BloomModel). 
  
  Model BloombergGPT posiada  50 mld parametrów oraz ponad 700 mld tokenów (aczkolwiek finalna wersja modelu zdołała przeprocesować w procesie uczenia modelu 570 z 710 mld dostępnych tokenów, nie wykorzystując zatem wszystkich przygotowanych zasobów).   

  Tokenizacja w ujęciu machine learningowym oznacza podział analizowanego tekstu na tzw. tokeny, którymi mogą być zdania, słowa, części słów, cyfry. Algorytmy  potrzebują rozłożyć tekst na „czynniki pierwsze”, by następnie móc efektywniej przeprowadzać na nim kolejne operacje i wyciągać wnioski. Dla naszej „maszyny” nie ma takiego znaczenia wolumen obrabianego tekstu, a to, ile finalnie tokenów do analizy z niego otrzymamy. Duża liczba tokenów przemawia na korzyść analizowanego modelu.

  Ciekawym niuansem są dane treningowe, które posłużyły do wyuczenia modelu BloombergGPT (ang. „training data”). Firma Bloomberg w swoim komunikacie prasowym dotyczącym publikacji wyraźnie podkreślała znaczenie „wysoce jakościowego i wyspecjalizowanego” wsadu danych do trenowania modelu. Dane pochodziły ze źródeł własnych przedsiębiorstwa, zbieranych przez 40 lat jego pracy lub z danych zewnętrznych (publicznych). W przypadku tych drugich, zdecydowano się na uwzględnienie jedynie tych zweryfikowanych i wstępnie przeprocesowanych pod wymagania uczenia maszynowego. 
  
  Pokrótce (szczegóły Paper, str. 5-6):
  * Dane własne, w tym serwis Bloomberg (język angielski) – 77% dokumentów, finalnie 51% tokenów = 363 mld tokenów,
  *	Dane publiczne (język angielski) – 23% dokumentów,  finalnie 49% tokenów = 345 mld tokenów.
 
  W skład danych publicznych (open source), na których trenowany został model, wybrane zostały dwa duże publiczne data sety, zwane The Pile oraz C4. Zostały one wstępnie przeprocesowane i oczyszczone przez swoich autorów, dzięki czemu są chętnie używane do uczenia nowych LLM-ów. Dodatkowo w dane publiczne włączono także świeże, nieoczyszczone dane z Wikipedii (od 1 lipca 2022 r., starsza wersja Wikipedii była już częścią The Pile oraz C4).

  Jako dane własne Bloomberg deklaruje przygotowany przez siebie zbiór danych FinPile. Jednakże pewnym zaskoczeniem jest, iż większość jego treści… dostępna jest publicznie w Internecie w formie artykułów prasowych czy notatek social media. Tylko niewielka część FinPile (poniżej 1%) to stricte finansowe dokumenty zastrzeżone przez Bloomberga, jakimi mogłyby być przykładowo pełne sprawozdania finansowe firm i spółek zależnych, raporty finansowe, analizy konsultingowe, dokumentacja wewnętrzna dotycząca fuzji i przejęć, związana z wejściem na giełdę i inne. Możnaby się spodziewać, iż udział takich danych w trenowaniu modelu będzie znacznie większy, ponieważ wydaje się, iż wokół nich firma Bloomberg chce budować swoją przewagę konkurencyjną. Tymczasem okazuje się, iż próg wejścia w specjalizację finansową dla innych modeli może nie być aż tak wysoki, skoro zdecydowana większość danych jest ogólnodostępna do pobrania w Internecie. W związku z powyższym należy też mieć świadomość, iż specjalizacja finansowa modelu BloombergGPT będzie prawdopodobnie dawała najlepsze efekty w analizach krótkich artykułów prasowych i notatek social media. Nie wiadomo, czy tak samo dobrze model radziłby sobie z analizą wielostronicowych i wielowątkowych dokumentów finansowych. Stąd też nasuwa się ciekawe pytanie, czy w przypadku takiej dokumentacji BloombergGPT “wygrałby” z innymi niewyspecjalizowanymi modelami, takimi jaki ChatGPT czy Bard, o których wiemy, że są w stanie sprostać takim wymaganiom? 

  Warto też wspomnieć, iż FinPile ani żadna jego część nie zostały udostępnione przez Bloomberga publicznie. Oczywiście przygotowanie zbioru danych pod uczenie maszynowe nie polega tylko i wyłącznie na zebraniu danych; dane te są także wstępnie przeprocesowane, oczyszczane i otagowane, kosztuje to czas i środki. Mimo to pojawiły się głosy ze środowiska, iż skoro firma chętnie korzysta dla własnych celów z cudzych opracowań (jak wcześniej wspomniane The Pile oraz C4), mogłaby dorzucić swoją cegiełkę do rozwoju branży zamiast być wyłącznie jej beneficjentem. 

  Przyjrzyjmy się teraz stosunkowi danych własnych do publicznych. Pierwsze co nasuwa się na myśl, to o ile faktycznie pod względem ilości dokumentów użytych do trenowania modelu dane własne w posiadaniu firmy Bloomberg (FinPile) znacząco przeważają, to już pod względem finalnego efektu tokenizacji otrzymujemy stosunek tokenów własnych do publicznych praktycznie 1:1. Co to oznacza w praktyce? Wydaje się, iż firmie Bloomberg zależało, aby BloombergGPT uzyskał dobre wyniki w domenie finansowej, w tym “nauczył się” korzystać z własnych zbiorów danych, ale także umiał pracować z różnorodnymi zagadnieniami i mógł być poddany ocenie na równi z innymi modelami językowymi.   

  Nie sposób nie wspomnieć o doborze konkurencyjnych modeli do analizy wyników BloombergGPT. Firma Bloomberg precyzuje, iż za kluczowe parametry w wyborze modeli do analizy porównawczej uznała: rozmiar modelu, typ analizowanych przez model danych (ang. „training data”), ogólną skuteczność modelu oraz jego dostępność (Paper, str. 17). Na ostatni parametr położono szczególny nacisk wspominając, iż model GPT-3 (pierwowzór na którym zbudowany został ChatGPT) nie był w danym czasie w pełni dostępny, a jedynie możliwe było wykorzystanie części z jego upublicznionych wyników jako dodatkowy punkt odniesienia. 

  Na tej podstawie do analizy porównawczej BloombergGPT (50 mld parametrów) dobrano następujące LLMy oraz podano krótkie uzasadnienia tych wyborów (Paper, str. 17):  
  * GPT-NeoX (20 mld parametrów) - model o najlepszych rezultatach wśród modeli do 50 mld parametrów,  
  * OPT (66 mld parametrów) - rozmiar i struktura obu modeli jest podobna, 
  * Bloom (176 mld parametrów) - model jest znacznie większy oraz został trenowany na danych w różnych językach, ale architektura obu modeli i oprogramowanie wspierające działanie modelu (tzw. “stack technologiczny”) są podobne. Warto tu ponownie wspomnieć, iż BloombergGPT powstał w oparciu o model Bloom. 

  Firma dodała także, iż „gdzie jest to możliwe odnosi wyniki także do modelu GPT-3”, ale zdarza się to wybiórczo. Pod względem liczby parametrów GPT-3 przewyższa BloombergGPT ponad 3-krotnie - jest znacznie większym modelem, porównywalnym do modelu Bloom. Jednakże ChatGPT wydaje się być obecnie najbardziej popularnym wśród konsumentów LLMem, stąd też porównywalne lub lepsze wyniki BloombergGPT byłyby znaczącą informacją dla zainteresowanych odbiorców, iż jest warty zaufania. Dodatkowo, w publikacji (Paper), która ukazała się już po upublicznieniu dostępu do ChatGPT, pada stwierdzenie, iż BloombergGPT w wielu zagadnieniach nie ustępuje modelowi GPT3, warto byłoby więc mieć do tego pełną skalę porównawczą. Ciężko rozstrzygnąć, czy pełne porównanie obu modeli rzeczywiście nie było możliwe, czy firma Bloomberg miała obiekcje do udostępnienia swoich danych, aby to porównanie przeprowadzić, czy też nie wszędzie podawanie wyników byłoby po prostu wygodne.  

-------------------------------------------------------------------

## BloombergGPT – podsumowanie i niuanse

-------------------------------------------------------------------

## Bibliografia




